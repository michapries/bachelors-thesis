{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Preprocessing\n",
    "2. Data Extraction\n",
    "3. Data Exploration\n",
    "4. **Model**\n",
    "\n",
    "This file initializes the model and makes predictions too."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature dataframe from pickle file\n",
    "df = pd.read_pickle('feature_frame.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HomeID</th>\n",
       "      <th>AwayID</th>\n",
       "      <th>FTHG</th>\n",
       "      <th>FTAG</th>\n",
       "      <th>FTR</th>\n",
       "      <th>Date</th>\n",
       "      <th>H_WIN_PCT_home</th>\n",
       "      <th>H_DRAW_PCT_home</th>\n",
       "      <th>A_WIN_PCT_home</th>\n",
       "      <th>A_DRAW_PCT_home</th>\n",
       "      <th>...</th>\n",
       "      <th>REL_PTS_1_away</th>\n",
       "      <th>REL_PTS_2_away</th>\n",
       "      <th>REL_PTS_3_away</th>\n",
       "      <th>REL_PTS_4_away</th>\n",
       "      <th>REL_PTS_5_away</th>\n",
       "      <th>REL_PTS_N-0_away</th>\n",
       "      <th>REL_PTS_N-1_away</th>\n",
       "      <th>REL_PTS_N-2_away</th>\n",
       "      <th>REL_PTS_N-3_away</th>\n",
       "      <th>REL_PTS_N-4_away</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1397</th>\n",
       "      <td>13</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-02-12</td>\n",
       "      <td>0.394737</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.078947</td>\n",
       "      <td>0.342105</td>\n",
       "      <td>...</td>\n",
       "      <td>1.115385</td>\n",
       "      <td>1.083077</td>\n",
       "      <td>1.076923</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>-0.230769</td>\n",
       "      <td>-0.153846</td>\n",
       "      <td>-0.116923</td>\n",
       "      <td>-0.115385</td>\n",
       "      <td>-0.038462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>22</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2011-12-27</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>...</td>\n",
       "      <td>0.264706</td>\n",
       "      <td>0.264706</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.346405</td>\n",
       "      <td>-0.352941</td>\n",
       "      <td>-1.568627</td>\n",
       "      <td>-1.457516</td>\n",
       "      <td>-1.346405</td>\n",
       "      <td>-1.294118</td>\n",
       "      <td>-1.235294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2011-05-01</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>...</td>\n",
       "      <td>0.914286</td>\n",
       "      <td>0.828571</td>\n",
       "      <td>0.742857</td>\n",
       "      <td>0.616450</td>\n",
       "      <td>0.446218</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>-0.171429</td>\n",
       "      <td>-0.171429</td>\n",
       "      <td>-0.085714</td>\n",
       "      <td>-0.057143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4640</th>\n",
       "      <td>51</td>\n",
       "      <td>49</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-05-10</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>...</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.701426</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.580214</td>\n",
       "      <td>-0.359180</td>\n",
       "      <td>-0.328877</td>\n",
       "      <td>-0.205882</td>\n",
       "      <td>-0.088235</td>\n",
       "      <td>-0.088235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8772</th>\n",
       "      <td>82</td>\n",
       "      <td>71</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-04-22</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>...</td>\n",
       "      <td>1.439394</td>\n",
       "      <td>1.189394</td>\n",
       "      <td>1.126894</td>\n",
       "      <td>0.848485</td>\n",
       "      <td>0.845644</td>\n",
       "      <td>-0.560606</td>\n",
       "      <td>-0.404356</td>\n",
       "      <td>-0.248106</td>\n",
       "      <td>-0.123106</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 91 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      HomeID  AwayID  FTHG  FTAG  FTR        Date  H_WIN_PCT_home  \\\n",
       "1397      13      21     1     1    0  2014-02-12        0.394737   \n",
       "557       22       5     0     2    2  2011-12-27        0.500000   \n",
       "347        8      17     3     0    1  2011-05-01        0.647059   \n",
       "4640      51      49     2     1    1  2014-05-10        0.636364   \n",
       "8772      82      71     3     2    1  2017-04-22        0.473684   \n",
       "\n",
       "      H_DRAW_PCT_home  A_WIN_PCT_home  A_DRAW_PCT_home  ...  REL_PTS_1_away  \\\n",
       "1397         0.421053        0.078947         0.342105  ...        1.115385   \n",
       "557          0.250000        0.111111         0.444444  ...        0.264706   \n",
       "347          0.235294        0.235294         0.176471  ...        0.914286   \n",
       "4640         0.181818        0.470588         0.176471  ...        1.500000   \n",
       "8772         0.263158        0.307692         0.307692  ...        1.439394   \n",
       "\n",
       "      REL_PTS_2_away  REL_PTS_3_away  REL_PTS_4_away  REL_PTS_5_away  \\\n",
       "1397        1.083077        1.076923        0.961538        0.846154   \n",
       "557         0.264706        0.000000       -0.346405       -0.352941   \n",
       "347         0.828571        0.742857        0.616450        0.446218   \n",
       "4640        0.941176        0.701426        0.647059        0.580214   \n",
       "8772        1.189394        1.126894        0.848485        0.845644   \n",
       "\n",
       "      REL_PTS_N-0_away  REL_PTS_N-1_away  REL_PTS_N-2_away  REL_PTS_N-3_away  \\\n",
       "1397         -0.230769         -0.153846         -0.116923         -0.115385   \n",
       "557          -1.568627         -1.457516         -1.346405         -1.294118   \n",
       "347          -0.200000         -0.171429         -0.171429         -0.085714   \n",
       "4640         -0.359180         -0.328877         -0.205882         -0.088235   \n",
       "8772         -0.560606         -0.404356         -0.248106         -0.123106   \n",
       "\n",
       "      REL_PTS_N-4_away  \n",
       "1397         -0.038462  \n",
       "557          -1.235294  \n",
       "347          -0.057143  \n",
       "4640         -0.088235  \n",
       "8772          0.000000  \n",
       "\n",
       "[5 rows x 91 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting target variables and features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# _WICHTIG: Das hier muss auf neue columns angepasst werden (z.B. season)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If True, the goal difference for a specific game is seen as the target variable.\n",
    "# (e.g. -3 for a game outcome of 1:4, or 2 for 3:1) .\n",
    "#\n",
    "# If False, we just want to predict the winner.\n",
    "# 1 = Home team wins, 0 = Draw, 2 = Away team wins\n",
    "predict_goal_difference = False\n",
    "\n",
    "if predict_goal_difference:\n",
    "    y = df['FTHG'] - df['FTAG']\n",
    "else:\n",
    "    y = df['FTR']\n",
    "    \n",
    "# Remove unnecessary columns (IDs etc.) from features\n",
    "X = df.iloc[:,6:].drop(['season', 'GAME_CNT_AFTER_GAME_home', 'GAME_CNT_AFTER_GAME_away', 'league'], axis=1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.iloc[:,6:].drop(['season', 'GAME_CNT_AFTER_GAME_home', 'GAME_CNT_AFTER_GAME_away'], axis=1).columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ranked Probability Score (RPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rps(pred, actual_value, r=3):\n",
    "    '''Returns the ranked probability score for a single given game.\n",
    "    (see Hubacek paper for formula)\n",
    "    \n",
    "    Arguments:\n",
    "    pred -- predicted results; in vector form (e.g. [0.1, 0.6, 0.3])\n",
    "    actual_value -- actual result (0, 1 or 2); not in vector form yet\n",
    "    r -- number of categories (3 for football)\n",
    "    '''\n",
    "    value_vec = [0, 0, 0]\n",
    "    \n",
    "    # Bring value_vec into 1, 0, 2 order\n",
    "    if actual_value == 0:\n",
    "        value_vec[1] = 1\n",
    "    elif actual_value == 2:\n",
    "        value_vec[0] == 1\n",
    "    elif actual_value == 1:\n",
    "        value_vec[2] == 1\n",
    "    else:\n",
    "        raise Exception('Prediction was not in [1, 0, 2].')\n",
    "    #value_vec = [0, 0, 1]\n",
    "    \n",
    "    #pred[0], pred[1] = pred[1], pred[0]\n",
    "    \n",
    "    pred[0], pred[1], pred[2] = pred[2], pred[0], pred[1]   # order: loss, draw, win\n",
    "    \n",
    "    #print(pred)\n",
    "    \n",
    "    rps = 0\n",
    "    \n",
    "    for i in range(0, r-1):    # r-1 becomes r because of the exclusion of range()\n",
    "        bracket_part = 0\n",
    "        for j in range(0, i+1):    # same for i and i+1\n",
    "            bracket_part += pred[j] - value_vec[j]\n",
    "        \n",
    "        rps += np.square(bracket_part)\n",
    "    \n",
    "    rps *= 1 / (r - 1)\n",
    "    \n",
    "    return rps\n",
    "\n",
    "\n",
    "# To be used as eval_metric parameter\n",
    "def rps_eval_metric(y_true, y_pred):\n",
    "    return rps(y_pred, y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apparently the random states are pretty important. 21 works very well on RPS and test accuracy, 16 only on accuracy.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.222, random_state=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find best value for *n_estimators*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# We start with n_estimators=50...\n",
    "xgb_cl = xgb.XGBClassifier(objective='multi:softmax', n_estimators=50, seed=16)\n",
    "# ...and then validate it to find the lowest loss.\n",
    "op = xgb_cl.fit(X_train, y_train, early_stopping_rounds=900, eval_metric='mlogloss', eval_set=[(X_test, y_test)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = [0.001, 0.01, 0.1, 0.2, 0.3]\n",
    "n_estimators = [4, 8, 16, 32]\n",
    "param_grid = dict(learning_rate=learning_rate, n_estimators=n_estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python38\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:29:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Best: 0.475635 using {'learning_rate': 0.2, 'n_estimators': 8}\n"
     ]
    }
   ],
   "source": [
    "# I tried to do Grid Search here, but the \n",
    "\n",
    "grid = GridSearchCV(estimator=xgb_cl, param_grid=param_grid, n_jobs=8, cv=3)\n",
    "grid_result = grid.fit(X, y)\n",
    "\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use best parameters to fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_estimators=8 had the lowest loss, so we overwrite the previous model.b\n",
    "xgb_cl = xgb.XGBClassifier(objective='multi:softprob', n_estimators=8, seed=16, learning_rate=0.3, eval_metric=rps_eval_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python38\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:04:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1,\n",
       "              eval_metric=<function rps_eval_metric at 0x000001E22331BC10>,\n",
       "              gamma=0, gpu_id=-1, importance_type='gain',\n",
       "              interaction_constraints='', learning_rate=0.3, max_delta_step=0,\n",
       "              max_depth=6, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=8, n_jobs=8,\n",
       "              num_parallel_tree=1, objective='multi:softprob', random_state=16,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=None, seed=16,\n",
       "              subsample=1, tree_method='exact', validate_parameters=1,\n",
       "              verbosity=None)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_cl.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.6344755970924195\n"
     ]
    }
   ],
   "source": [
    "preds = xgb_cl.predict(X_test)\n",
    "accuracy = float(np.sum(preds == y_test))/y_test.shape[0]\n",
    "\n",
    "print(f'accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on train set: 0.6718364121307913\n"
     ]
    }
   ],
   "source": [
    "# Looking at train set accuracy to get an intuition of how much the model overfits\n",
    "preds = xgb_cl.predict(X_train)\n",
    "accuracy = float(np.sum(preds == y_train))/y_train.shape[0]\n",
    "\n",
    "print(f'accuracy on train set: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21778030378136548"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predictions in form of [0.2, 0.5, 0.3] in the order of draw, home win, away win.\n",
    "# This is because it gets ordered like 0, 1, 2.\n",
    "proba_preds = xgb_cl.predict_proba(X_test)\n",
    "\n",
    "# List of RPS scores for every game in the test set.\n",
    "# Important to use iloc for y_test, otherwise indices would be wrong\n",
    "rps_list = [rps(pred, y_test.iloc[i]) for i, pred in enumerate(proba_preds)]\n",
    "\n",
    "# Average ranked probability score.\n",
    "np.mean(rps_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
