{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Preprocessing\n",
    "2. Data Extraction\n",
    "3. Data Exploration\n",
    "4. **Model**\n",
    "\n",
    "This file initializes the model and makes predictions too."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature dataframe from pickle file\n",
    "df = pd.read_pickle('feature_frame.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HomeID</th>\n",
       "      <th>AwayID</th>\n",
       "      <th>FTHG</th>\n",
       "      <th>FTAG</th>\n",
       "      <th>FTR</th>\n",
       "      <th>H_WIN_PCT_home</th>\n",
       "      <th>H_DRAW_PCT_home</th>\n",
       "      <th>A_WIN_PCT_home</th>\n",
       "      <th>A_DRAW_PCT_home</th>\n",
       "      <th>H_WIN_PCT_away</th>\n",
       "      <th>...</th>\n",
       "      <th>A_RTG_away</th>\n",
       "      <th>EGD</th>\n",
       "      <th>EPTS_PR_home</th>\n",
       "      <th>EPTS_PR_away</th>\n",
       "      <th>RED_home</th>\n",
       "      <th>RED_away</th>\n",
       "      <th>H_ST_home</th>\n",
       "      <th>H_ST_away</th>\n",
       "      <th>A_ST_home</th>\n",
       "      <th>A_ST_away</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9416</th>\n",
       "      <td>81</td>\n",
       "      <td>79</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.729730</td>\n",
       "      <td>0.189189</td>\n",
       "      <td>0.763158</td>\n",
       "      <td>0.131579</td>\n",
       "      <td>0.486486</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.063481</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>18.621622</td>\n",
       "      <td>16.027027</td>\n",
       "      <td>14.210526</td>\n",
       "      <td>13.026316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.315577</td>\n",
       "      <td>0.274067</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12.200000</td>\n",
       "      <td>13.600000</td>\n",
       "      <td>10.200000</td>\n",
       "      <td>8.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1232</th>\n",
       "      <td>26</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>...</td>\n",
       "      <td>0.046905</td>\n",
       "      <td>0.107180</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.750000</td>\n",
       "      <td>12.157895</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>8.405405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10425</th>\n",
       "      <td>106</td>\n",
       "      <td>102</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.236842</td>\n",
       "      <td>0.236842</td>\n",
       "      <td>0.236842</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.160812</td>\n",
       "      <td>0.957403</td>\n",
       "      <td>1.50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14.105263</td>\n",
       "      <td>14.157895</td>\n",
       "      <td>10.921053</td>\n",
       "      <td>11.026316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1799</th>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.675676</td>\n",
       "      <td>0.270270</td>\n",
       "      <td>0.589744</td>\n",
       "      <td>0.128205</td>\n",
       "      <td>0.435897</td>\n",
       "      <td>...</td>\n",
       "      <td>0.389261</td>\n",
       "      <td>-0.483171</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16.297297</td>\n",
       "      <td>13.333333</td>\n",
       "      <td>12.794872</td>\n",
       "      <td>10.432432</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       HomeID  AwayID  FTHG  FTAG  FTR  H_WIN_PCT_home  H_DRAW_PCT_home  \\\n",
       "9416       81      79     2     1    1        0.729730         0.189189   \n",
       "106         4      13     2     0    1        0.400000         0.600000   \n",
       "1232       26       4     1     0    1        0.500000         0.500000   \n",
       "10425     106     102     1     0    1        0.526316         0.236842   \n",
       "1799       10      15     3     0    1        0.675676         0.270270   \n",
       "\n",
       "       A_WIN_PCT_home  A_DRAW_PCT_home  H_WIN_PCT_away  ...  A_RTG_away  \\\n",
       "9416         0.763158         0.131579        0.486486  ...    0.000000   \n",
       "106          0.000000         0.600000        0.400000  ...   -0.315577   \n",
       "1232         0.200000         0.000000        0.315789  ...    0.046905   \n",
       "10425        0.236842         0.236842        0.526316  ...   -0.160812   \n",
       "1799         0.589744         0.128205        0.435897  ...    0.389261   \n",
       "\n",
       "            EGD  EPTS_PR_home  EPTS_PR_away  RED_home  RED_away  H_ST_home  \\\n",
       "9416   0.063481          0.75          0.00         0         1  18.621622   \n",
       "106    0.274067          1.00          1.00         1         1  12.200000   \n",
       "1232   0.107180          1.00          1.00         0         0   9.750000   \n",
       "10425  0.957403          1.50          0.75         1         1  14.105263   \n",
       "1799  -0.483171          1.00          0.00         0         0  16.297297   \n",
       "\n",
       "       H_ST_away  A_ST_home  A_ST_away  \n",
       "9416   16.027027  14.210526  13.026316  \n",
       "106    13.600000  10.200000   8.800000  \n",
       "1232   12.157895   9.000000   8.405405  \n",
       "10425  14.157895  10.921053  11.026316  \n",
       "1799   13.333333  12.794872  10.432432  \n",
       "\n",
       "[5 rows x 65 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting target variables and features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If True, the goal difference for a specific game is seen as the target variable.\n",
    "# (e.g. -3 for a game outcome of 1:4, or 2 for 3:1) .\n",
    "#\n",
    "# If False, we just want to predict the winner.\n",
    "# 1 = Home team wins, 0 = Draw, 2 = Away team wins\n",
    "predict_goal_difference = False\n",
    "\n",
    "if predict_goal_difference:\n",
    "    y = df['FTHG'] - df['FTAG']\n",
    "else:\n",
    "    y = df['FTR']\n",
    "\n",
    "X = df.iloc[:,5:]    # Remove unnecessary columns (IDs etc.) from features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ranked Probability Score (RPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rps(pred, actual_value, r=3):\n",
    "    '''Returns the ranked probability score for a single given game.\n",
    "    (see Hubacek paper for formula)\n",
    "    \n",
    "    Arguments:\n",
    "    pred -- predicted results; in vector form (e.g. [0.1, 0.6, 0.3])\n",
    "    actual_value -- actual result (0, 1 or 2); not in vector form yet\n",
    "    r -- number of categories (3 for football)\n",
    "    '''\n",
    "    value_vec = [0, 0, 0]\n",
    "    \n",
    "    # Bring value_vec into 1, 0, 2 order\n",
    "    if actual_value == 0:\n",
    "        value_vec[1] = 1\n",
    "    elif actual_value == 2:\n",
    "        value_vec[0] == 1\n",
    "    elif actual_value == 1:\n",
    "        value_vec[2] == 1\n",
    "    else:\n",
    "        raise Exception('Prediction was not in [1, 0, 2].')\n",
    "    #value_vec = [0, 0, 1]\n",
    "    \n",
    "    #pred[0], pred[1] = pred[1], pred[0]\n",
    "    \n",
    "    pred[0], pred[1], pred[2] = pred[2], pred[0], pred[1]   # order: loss, draw, win\n",
    "    \n",
    "    #print(pred)\n",
    "    \n",
    "    rps = 0\n",
    "    \n",
    "    for i in range(0, r-1):    # r-1 becomes r because of the exclusion of range()\n",
    "        bracket_part = 0\n",
    "        for j in range(0, i+1):    # same for i and i+1\n",
    "            bracket_part += pred[j] - value_vec[j]\n",
    "        \n",
    "        rps += np.square(bracket_part)\n",
    "    \n",
    "    rps *= 1 / (r - 1)\n",
    "    \n",
    "    return rps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apparently the random states are pretty important. 21 works very well on RPS and test accuracy, 16 only on accuracy.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.222, random_state=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find best value for *n_estimators*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-mlogloss:1.05159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python38\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalidation_0-mlogloss:1.02520\n",
      "[2]\tvalidation_0-mlogloss:1.00897\n",
      "[3]\tvalidation_0-mlogloss:0.99943\n",
      "[4]\tvalidation_0-mlogloss:0.99461\n",
      "[5]\tvalidation_0-mlogloss:0.98913\n",
      "[6]\tvalidation_0-mlogloss:0.98577\n",
      "[7]\tvalidation_0-mlogloss:0.98409\n",
      "[8]\tvalidation_0-mlogloss:0.98478\n",
      "[9]\tvalidation_0-mlogloss:0.98430\n",
      "[10]\tvalidation_0-mlogloss:0.98471\n",
      "[11]\tvalidation_0-mlogloss:0.98532\n",
      "[12]\tvalidation_0-mlogloss:0.98546\n",
      "[13]\tvalidation_0-mlogloss:0.98485\n",
      "[14]\tvalidation_0-mlogloss:0.98523\n",
      "[15]\tvalidation_0-mlogloss:0.98631\n",
      "[16]\tvalidation_0-mlogloss:0.98643\n",
      "[17]\tvalidation_0-mlogloss:0.98745\n",
      "[18]\tvalidation_0-mlogloss:0.98898\n",
      "[19]\tvalidation_0-mlogloss:0.99127\n",
      "[20]\tvalidation_0-mlogloss:0.99189\n",
      "[21]\tvalidation_0-mlogloss:0.99234\n",
      "[22]\tvalidation_0-mlogloss:0.99355\n",
      "[23]\tvalidation_0-mlogloss:0.99401\n",
      "[24]\tvalidation_0-mlogloss:0.99533\n",
      "[25]\tvalidation_0-mlogloss:0.99560\n",
      "[26]\tvalidation_0-mlogloss:0.99618\n",
      "[27]\tvalidation_0-mlogloss:0.99740\n",
      "[28]\tvalidation_0-mlogloss:0.99772\n",
      "[29]\tvalidation_0-mlogloss:0.99915\n",
      "[30]\tvalidation_0-mlogloss:0.99921\n",
      "[31]\tvalidation_0-mlogloss:0.99964\n",
      "[32]\tvalidation_0-mlogloss:1.00000\n",
      "[33]\tvalidation_0-mlogloss:1.00201\n",
      "[34]\tvalidation_0-mlogloss:1.00333\n",
      "[35]\tvalidation_0-mlogloss:1.00369\n",
      "[36]\tvalidation_0-mlogloss:1.00436\n",
      "[37]\tvalidation_0-mlogloss:1.00502\n",
      "[38]\tvalidation_0-mlogloss:1.00482\n",
      "[39]\tvalidation_0-mlogloss:1.00612\n",
      "[40]\tvalidation_0-mlogloss:1.00754\n",
      "[41]\tvalidation_0-mlogloss:1.00896\n",
      "[42]\tvalidation_0-mlogloss:1.00979\n",
      "[43]\tvalidation_0-mlogloss:1.01120\n",
      "[44]\tvalidation_0-mlogloss:1.01267\n",
      "[45]\tvalidation_0-mlogloss:1.01460\n",
      "[46]\tvalidation_0-mlogloss:1.01649\n",
      "[47]\tvalidation_0-mlogloss:1.01642\n",
      "[48]\tvalidation_0-mlogloss:1.01676\n",
      "[49]\tvalidation_0-mlogloss:1.01686\n"
     ]
    }
   ],
   "source": [
    "# We start with n_estimators=50...\n",
    "xgb_cl = xgb.XGBClassifier(objective='multi:softmax', n_estimators=50, seed=16)\n",
    "# ...and then validate it to find the lowest loss.\n",
    "op = xgb_cl.fit(X_train, y_train, early_stopping_rounds=900, eval_metric='mlogloss', eval_set=[(X_test, y_test)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = [0.001, 0.01, 0.1, 0.2, 0.3]\n",
    "n_estimators = [4, 8, 16, 32]\n",
    "param_grid = dict(learning_rate=learning_rate, n_estimators=n_estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python38\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:29:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Best: 0.475635 using {'learning_rate': 0.2, 'n_estimators': 8}\n"
     ]
    }
   ],
   "source": [
    "# I tried to do Grid Search here, but the \n",
    "\n",
    "grid = GridSearchCV(estimator=xgb_cl, param_grid=param_grid, n_jobs=8, cv=3)\n",
    "grid_result = grid.fit(X, y)\n",
    "\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use best parameters to fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_estimators=8 had the lowest loss, so we overwrite the previous model.b\n",
    "xgb_cl = xgb.XGBClassifier(objective='multi:softprob', n_estimators=8, seed=16, learning_rate=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python38\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:55:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.3, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=8, n_jobs=8, num_parallel_tree=1,\n",
       "              objective='multi:softprob', random_state=16, reg_alpha=0,\n",
       "              reg_lambda=1, scale_pos_weight=None, seed=16, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_cl.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.5309795777085496\n"
     ]
    }
   ],
   "source": [
    "preds = xgb_cl.predict(X_test)\n",
    "accuracy = float(np.sum(preds == y_test))/y_test.shape[0]\n",
    "\n",
    "print(f'accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on train set: 0.6137508643682703\n"
     ]
    }
   ],
   "source": [
    "# Looking at train set accuracy to get an intuition of how much the model overfits\n",
    "preds = xgb_cl.predict(X_train)\n",
    "accuracy = float(np.sum(preds == y_train))/y_train.shape[0]\n",
    "\n",
    "print(f'accuracy on train set: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20160546311142438"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predictions in form of [0.2, 0.5, 0.3] in the order of draw, home win, away win.\n",
    "# This is because it gets ordered like 0, 1, 2.\n",
    "proba_preds = xgb_cl.predict_proba(X_test)\n",
    "\n",
    "# List of RPS scores for every game in the test set.\n",
    "# Important to use iloc for y_test, otherwise indices would be wrong\n",
    "rps_list = [rps(pred, y_test.iloc[i]) for i, pred in enumerate(proba_preds)]\n",
    "\n",
    "# Average ranked probability score.\n",
    "np.mean(rps_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
