{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Preprocessing\n",
    "2. Data Extraction\n",
    "3. Data Exploration\n",
    "4. **Model**\n",
    "\n",
    "This file initializes the model and makes predictions too."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature dataframe from pickle file\n",
    "df = pd.read_pickle('feature_frame.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HomeID</th>\n",
       "      <th>AwayID</th>\n",
       "      <th>FTHG</th>\n",
       "      <th>FTAG</th>\n",
       "      <th>FTR</th>\n",
       "      <th>H_WIN_PCT_home</th>\n",
       "      <th>H_DRAW_PCT_home</th>\n",
       "      <th>A_WIN_PCT_home</th>\n",
       "      <th>A_DRAW_PCT_home</th>\n",
       "      <th>H_WIN_PCT_away</th>\n",
       "      <th>...</th>\n",
       "      <th>H_WIN_PCT_league</th>\n",
       "      <th>DRAW_PCT_league</th>\n",
       "      <th>TEAM_CNT_league</th>\n",
       "      <th>GD_STD_league</th>\n",
       "      <th>RND_CNT_league</th>\n",
       "      <th>H_RTG_home</th>\n",
       "      <th>A_RTG_home</th>\n",
       "      <th>H_RTG_away</th>\n",
       "      <th>A_RTG_away</th>\n",
       "      <th>EGD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10113</th>\n",
       "      <td>109</td>\n",
       "      <td>99</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.509804</td>\n",
       "      <td>0.225490</td>\n",
       "      <td>20</td>\n",
       "      <td>1.328656</td>\n",
       "      <td>38</td>\n",
       "      <td>0.389185</td>\n",
       "      <td>0.005772</td>\n",
       "      <td>0.116755</td>\n",
       "      <td>0.019238</td>\n",
       "      <td>0.333243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4487</th>\n",
       "      <td>38</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.343750</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.314286</td>\n",
       "      <td>0.257143</td>\n",
       "      <td>0.441176</td>\n",
       "      <td>...</td>\n",
       "      <td>0.440397</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>18</td>\n",
       "      <td>1.304943</td>\n",
       "      <td>34</td>\n",
       "      <td>0.123684</td>\n",
       "      <td>-0.001480</td>\n",
       "      <td>0.037105</td>\n",
       "      <td>-0.004934</td>\n",
       "      <td>0.103376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9579</th>\n",
       "      <td>74</td>\n",
       "      <td>65</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.552632</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.289474</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>...</td>\n",
       "      <td>0.437337</td>\n",
       "      <td>0.244125</td>\n",
       "      <td>20</td>\n",
       "      <td>1.198641</td>\n",
       "      <td>38</td>\n",
       "      <td>-0.161140</td>\n",
       "      <td>-0.045249</td>\n",
       "      <td>-0.048342</td>\n",
       "      <td>-0.150829</td>\n",
       "      <td>-0.008921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9890</th>\n",
       "      <td>110</td>\n",
       "      <td>109</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.520690</td>\n",
       "      <td>0.210345</td>\n",
       "      <td>20</td>\n",
       "      <td>1.278651</td>\n",
       "      <td>38</td>\n",
       "      <td>0.068156</td>\n",
       "      <td>-0.147384</td>\n",
       "      <td>0.020447</td>\n",
       "      <td>-0.491280</td>\n",
       "      <td>0.511713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2735</th>\n",
       "      <td>21</td>\n",
       "      <td>34</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.378378</td>\n",
       "      <td>0.189189</td>\n",
       "      <td>0.236842</td>\n",
       "      <td>0.184211</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.461333</td>\n",
       "      <td>0.245333</td>\n",
       "      <td>20</td>\n",
       "      <td>1.244498</td>\n",
       "      <td>38</td>\n",
       "      <td>-0.213390</td>\n",
       "      <td>-0.026901</td>\n",
       "      <td>-0.064017</td>\n",
       "      <td>-0.089669</td>\n",
       "      <td>-0.106711</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       HomeID  AwayID  FTHG  FTAG  FTR  H_WIN_PCT_home  H_DRAW_PCT_home  \\\n",
       "10113     109      99     2     1    1        0.538462         0.269231   \n",
       "4487       38      43     2     3    2        0.343750         0.187500   \n",
       "9579       74      65     2     0    1        0.552632         0.263158   \n",
       "9890      110     109     2     4    2        0.400000         0.200000   \n",
       "2735       21      34     2     0    1        0.378378         0.189189   \n",
       "\n",
       "       A_WIN_PCT_home  A_DRAW_PCT_home  H_WIN_PCT_away  ...  H_WIN_PCT_league  \\\n",
       "10113        0.600000         0.160000        0.560000  ...          0.509804   \n",
       "4487         0.314286         0.257143        0.441176  ...          0.440397   \n",
       "9579         0.500000         0.289474        0.210526  ...          0.437337   \n",
       "9890         0.214286         0.285714        0.533333  ...          0.520690   \n",
       "2735         0.236842         0.184211        0.250000  ...          0.461333   \n",
       "\n",
       "       DRAW_PCT_league  TEAM_CNT_league  GD_STD_league  RND_CNT_league  \\\n",
       "10113         0.225490               20       1.328656              38   \n",
       "4487          0.250000               18       1.304943              34   \n",
       "9579          0.244125               20       1.198641              38   \n",
       "9890          0.210345               20       1.278651              38   \n",
       "2735          0.245333               20       1.244498              38   \n",
       "\n",
       "       H_RTG_home  A_RTG_home  H_RTG_away  A_RTG_away       EGD  \n",
       "10113    0.389185    0.005772    0.116755    0.019238  0.333243  \n",
       "4487     0.123684   -0.001480    0.037105   -0.004934  0.103376  \n",
       "9579    -0.161140   -0.045249   -0.048342   -0.150829 -0.008921  \n",
       "9890     0.068156   -0.147384    0.020447   -0.491280  0.511713  \n",
       "2735    -0.213390   -0.026901   -0.064017   -0.089669 -0.106711  \n",
       "\n",
       "[5 rows x 57 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting target variables and features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If True, the goal difference for a specific game is seen as the target variable.\n",
    "# (e.g. -3 for a game outcome of 1:4, or 2 for 3:1) .\n",
    "#\n",
    "# If False, we just want to predict the winner.\n",
    "# 1 = Home team wins, 0 = Draw, 2 = Away team wins\n",
    "predict_goal_difference = False\n",
    "\n",
    "if predict_goal_difference:\n",
    "    y = df['FTHG'] - df['FTAG']\n",
    "else:\n",
    "    y = df['FTR']\n",
    "\n",
    "X = df.iloc[:,5:]    # Remove unnecessary columns (IDs etc.) from features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ranked Probability Score (RPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rps(pred, actual_value, r=3):\n",
    "    '''Returns the ranked probability score for a single given game.\n",
    "    (see Hubacek paper for formula)\n",
    "    \n",
    "    Arguments:\n",
    "    pred -- predicted results; in vector form (e.g. [0.1, 0.6, 0.3])\n",
    "    actual_value -- actual result (0, 1 or 2); not in vector form yet\n",
    "    r -- number of categories (3 for football)\n",
    "    '''\n",
    "    value_vec = [0, 0, 0]\n",
    "    \n",
    "    # Bring value_vec into 1, 0, 2 order\n",
    "    if actual_value == 0:\n",
    "        value_vec[1] = 1\n",
    "    elif actual_value == 2:\n",
    "        value_vec[0] == 1\n",
    "    elif actual_value == 1:\n",
    "        value_vec[2] == 1\n",
    "    else:\n",
    "        raise Exception('Prediction was not in [1, 0, 2].')\n",
    "    #value_vec = [0, 0, 1]\n",
    "    \n",
    "    #pred[0], pred[1] = pred[1], pred[0]\n",
    "    \n",
    "    pred[0], pred[1], pred[2] = pred[2], pred[0], pred[1]   # order: loss, draw, win\n",
    "    \n",
    "    #print(pred)\n",
    "    \n",
    "    rps = 0\n",
    "    \n",
    "    for i in range(0, r-1):    # r-1 becomes r because of the exclusion of range()\n",
    "        bracket_part = 0\n",
    "        for j in range(0, i+1):    # same for i and i+1\n",
    "            bracket_part += pred[j] - value_vec[j]\n",
    "        \n",
    "        rps += np.square(bracket_part)\n",
    "    \n",
    "    rps *= 1 / (r - 1)\n",
    "    \n",
    "    return rps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apparently the random states are pretty important. 21 works very well on RPS and test accuracy, 16 only on accuracy.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.222, random_state=21)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find best value for *n_estimators*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-mlogloss:1.05159\n",
      "[1]\tvalidation_0-mlogloss:1.02520\n",
      "[2]\tvalidation_0-mlogloss:1.00897\n",
      "[3]\tvalidation_0-mlogloss:0.99943\n",
      "[4]\tvalidation_0-mlogloss:0.99461\n",
      "[5]\tvalidation_0-mlogloss:0.98913\n",
      "[6]\tvalidation_0-mlogloss:0.98577\n",
      "[7]\tvalidation_0-mlogloss:0.98409\n",
      "[8]\tvalidation_0-mlogloss:0.98478\n",
      "[9]\tvalidation_0-mlogloss:0.98430\n",
      "[10]\tvalidation_0-mlogloss:0.98471\n",
      "[11]\tvalidation_0-mlogloss:0.98532\n",
      "[12]\tvalidation_0-mlogloss:0.98546\n",
      "[13]\tvalidation_0-mlogloss:0.98485\n",
      "[14]\tvalidation_0-mlogloss:0.98523\n",
      "[15]\tvalidation_0-mlogloss:0.98631\n",
      "[16]\tvalidation_0-mlogloss:0.98643\n",
      "[17]\tvalidation_0-mlogloss:0.98745\n",
      "[18]\tvalidation_0-mlogloss:0.98898\n",
      "[19]\tvalidation_0-mlogloss:0.99127\n",
      "[20]\tvalidation_0-mlogloss:0.99189\n",
      "[21]\tvalidation_0-mlogloss:0.99234\n",
      "[22]\tvalidation_0-mlogloss:0.99355\n",
      "[23]\tvalidation_0-mlogloss:0.99401\n",
      "[24]\tvalidation_0-mlogloss:0.99533\n",
      "[25]\tvalidation_0-mlogloss:0.99560\n",
      "[26]\tvalidation_0-mlogloss:0.99618\n",
      "[27]\tvalidation_0-mlogloss:0.99740\n",
      "[28]\tvalidation_0-mlogloss:0.99772\n",
      "[29]\tvalidation_0-mlogloss:0.99915\n",
      "[30]\tvalidation_0-mlogloss:0.99921\n",
      "[31]\tvalidation_0-mlogloss:0.99964\n",
      "[32]\tvalidation_0-mlogloss:1.00000\n",
      "[33]\tvalidation_0-mlogloss:1.00201\n",
      "[34]\tvalidation_0-mlogloss:1.00333\n",
      "[35]\tvalidation_0-mlogloss:1.00369\n",
      "[36]\tvalidation_0-mlogloss:1.00436\n",
      "[37]\tvalidation_0-mlogloss:1.00502\n",
      "[38]\tvalidation_0-mlogloss:1.00482\n",
      "[39]\tvalidation_0-mlogloss:1.00612\n",
      "[40]\tvalidation_0-mlogloss:1.00754\n",
      "[41]\tvalidation_0-mlogloss:1.00896\n",
      "[42]\tvalidation_0-mlogloss:1.00979\n",
      "[43]\tvalidation_0-mlogloss:1.01120\n",
      "[44]\tvalidation_0-mlogloss:1.01267\n",
      "[45]\tvalidation_0-mlogloss:1.01460\n",
      "[46]\tvalidation_0-mlogloss:1.01649\n",
      "[47]\tvalidation_0-mlogloss:1.01642\n",
      "[48]\tvalidation_0-mlogloss:1.01676\n",
      "[49]\tvalidation_0-mlogloss:1.01686\n"
     ]
    }
   ],
   "source": [
    "# We start with n_estimators=50...\n",
    "xgb_cl = xgb.XGBClassifier(objective='multi:softmax', n_estimators=50, seed=16)\n",
    "# ...and then validate it to find the lowest loss.\n",
    "op = xgb_cl.fit(X_train, y_train, early_stopping_rounds=900, eval_metric='mlogloss', eval_set=[(X_test, y_test)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = [0.001, 0.01, 0.1, 0.2, 0.3]\n",
    "n_estimators = [4, 8, 16, 32]\n",
    "param_grid = dict(learning_rate=learning_rate, n_estimators=n_estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python38\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:29:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Best: 0.475635 using {'learning_rate': 0.2, 'n_estimators': 8}\n"
     ]
    }
   ],
   "source": [
    "# I tried to do Grid Search here, but the \n",
    "\n",
    "grid = GridSearchCV(estimator=xgb_cl, param_grid=param_grid, n_jobs=8, cv=3)\n",
    "grid_result = grid.fit(X, y)\n",
    "\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use best parameters to fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_estimators=8 had the lowest loss, so we overwrite the previous model.b\n",
    "xgb_cl = xgb.XGBClassifier(objective='multi:softprob', n_estimators=8, seed=16, learning_rate=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:40:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.3, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=8, n_jobs=8, num_parallel_tree=1,\n",
       "              objective='multi:softprob', random_state=16, reg_alpha=0,\n",
       "              reg_lambda=1, scale_pos_weight=None, seed=16, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_cl.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.532017999307719\n"
     ]
    }
   ],
   "source": [
    "preds = xgb_cl.predict(X_test)\n",
    "accuracy = float(np.sum(preds == y_test))/y_test.shape[0]\n",
    "\n",
    "print(f'accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on train set: 0.620369455694952\n"
     ]
    }
   ],
   "source": [
    "# Looking at train set accuracy to get an intuition of how much the model overfits\n",
    "preds = xgb_cl.predict(X_train)\n",
    "accuracy = float(np.sum(preds == y_train))/y_train.shape[0]\n",
    "\n",
    "print(f'accuracy on train set: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20503750632251014"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predictions in form of [0.2, 0.5, 0.3] in the order of draw, home win, away win.\n",
    "# This is because it gets ordered like 0, 1, 2.\n",
    "proba_preds = xgb_cl.predict_proba(X_test)\n",
    "\n",
    "# List of RPS scores for every game in the test set.\n",
    "# Important to use iloc for y_test, otherwise indices would be wrong\n",
    "rps_list = [rps(pred, y_test.iloc[i]) for i, pred in enumerate(proba_preds)]\n",
    "\n",
    "# Average ranked probability score.\n",
    "np.mean(rps_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
