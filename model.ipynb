{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Preprocessing\n",
    "2. Data Extraction\n",
    "3. Data Exploration\n",
    "4. **Model**\n",
    "\n",
    "This file initializes the model and makes predictions too."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature dataframe from pickle file\n",
    "df = pd.read_pickle('feature_frame.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HomeID</th>\n",
       "      <th>AwayID</th>\n",
       "      <th>FTHG</th>\n",
       "      <th>FTAG</th>\n",
       "      <th>FTR</th>\n",
       "      <th>H_WIN_PCT_home</th>\n",
       "      <th>H_DRAW_PCT_home</th>\n",
       "      <th>A_WIN_PCT_home</th>\n",
       "      <th>A_DRAW_PCT_home</th>\n",
       "      <th>H_WIN_PCT_away</th>\n",
       "      <th>...</th>\n",
       "      <th>A_RTG_away</th>\n",
       "      <th>EGD</th>\n",
       "      <th>EPTS_PR_home</th>\n",
       "      <th>EPTS_PR_away</th>\n",
       "      <th>RED_home</th>\n",
       "      <th>RED_away</th>\n",
       "      <th>H_ST_home</th>\n",
       "      <th>H_ST_away</th>\n",
       "      <th>A_ST_home</th>\n",
       "      <th>A_ST_away</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4694</th>\n",
       "      <td>47</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.606061</td>\n",
       "      <td>0.212121</td>\n",
       "      <td>0.371429</td>\n",
       "      <td>0.228571</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>...</td>\n",
       "      <td>0.062300</td>\n",
       "      <td>-0.156056</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>16.242424</td>\n",
       "      <td>19.114286</td>\n",
       "      <td>11.885714</td>\n",
       "      <td>14.939394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8867</th>\n",
       "      <td>63</td>\n",
       "      <td>77</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.236842</td>\n",
       "      <td>0.184211</td>\n",
       "      <td>0.236842</td>\n",
       "      <td>0.394737</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.279358</td>\n",
       "      <td>0.419571</td>\n",
       "      <td>1.25</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>12.552632</td>\n",
       "      <td>10.552632</td>\n",
       "      <td>11.157895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10031</th>\n",
       "      <td>102</td>\n",
       "      <td>101</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.713681</td>\n",
       "      <td>0.766140</td>\n",
       "      <td>0.50</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14.523810</td>\n",
       "      <td>13.363636</td>\n",
       "      <td>11.545455</td>\n",
       "      <td>11.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3274</th>\n",
       "      <td>9</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.657895</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.512821</td>\n",
       "      <td>0.205128</td>\n",
       "      <td>0.351351</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027107</td>\n",
       "      <td>-0.007425</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>14.868421</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>12.076923</td>\n",
       "      <td>9.175000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7714</th>\n",
       "      <td>81</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>0.216216</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.289474</td>\n",
       "      <td>...</td>\n",
       "      <td>0.118904</td>\n",
       "      <td>-0.073598</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17.135135</td>\n",
       "      <td>10.868421</td>\n",
       "      <td>13.552632</td>\n",
       "      <td>9.810811</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       HomeID  AwayID  FTHG  FTAG  FTR  H_WIN_PCT_home  H_DRAW_PCT_home  \\\n",
       "4694       47      42     2     1    1        0.606061         0.212121   \n",
       "8867       63      77     1     0    1        0.368421         0.236842   \n",
       "10031     102     101     2     2    0        0.523810         0.333333   \n",
       "3274        9      29     2     2    0        0.657895         0.263158   \n",
       "7714       81      65     0     1    2        0.702703         0.216216   \n",
       "\n",
       "       A_WIN_PCT_home  A_DRAW_PCT_home  H_WIN_PCT_away  ...  A_RTG_away  \\\n",
       "4694         0.371429         0.228571        0.571429  ...    0.062300   \n",
       "8867         0.184211         0.236842        0.394737  ...   -0.279358   \n",
       "10031        0.136364         0.181818        0.500000  ...   -0.713681   \n",
       "3274         0.512821         0.205128        0.351351  ...    0.027107   \n",
       "7714         0.500000         0.263158        0.289474  ...    0.118904   \n",
       "\n",
       "            EGD  EPTS_PR_home  EPTS_PR_away  RED_home  RED_away  H_ST_home  \\\n",
       "4694  -0.156056          1.00          0.25         2         0  16.242424   \n",
       "8867   0.419571          1.25          1.25         0         0  12.500000   \n",
       "10031  0.766140          0.50          2.00         0         0  14.523810   \n",
       "3274  -0.007425          0.25          0.25         0         1  14.868421   \n",
       "7714  -0.073598          1.00          1.00         0         0  17.135135   \n",
       "\n",
       "       H_ST_away  A_ST_home  A_ST_away  \n",
       "4694   19.114286  11.885714  14.939394  \n",
       "8867   12.552632  10.552632  11.157895  \n",
       "10031  13.363636  11.545455  11.666667  \n",
       "3274   11.000000  12.076923   9.175000  \n",
       "7714   10.868421  13.552632   9.810811  \n",
       "\n",
       "[5 rows x 65 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting target variables and features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# _WICHTIG: Das hier muss auf neue columns angepasst werden (z.B. season)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If True, the goal difference for a specific game is seen as the target variable.\n",
    "# (e.g. -3 for a game outcome of 1:4, or 2 for 3:1) .\n",
    "#\n",
    "# If False, we just want to predict the winner.\n",
    "# 1 = Home team wins, 0 = Draw, 2 = Away team wins\n",
    "predict_goal_difference = False\n",
    "\n",
    "if predict_goal_difference:\n",
    "    y = df['FTHG'] - df['FTAG']\n",
    "else:\n",
    "    y = df['FTR']\n",
    "\n",
    "X = df.iloc[:,5:]    # Remove unnecessary columns (IDs etc.) from features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ranked Probability Score (RPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rps(pred, actual_value, r=3):\n",
    "    '''Returns the ranked probability score for a single given game.\n",
    "    (see Hubacek paper for formula)\n",
    "    \n",
    "    Arguments:\n",
    "    pred -- predicted results; in vector form (e.g. [0.1, 0.6, 0.3])\n",
    "    actual_value -- actual result (0, 1 or 2); not in vector form yet\n",
    "    r -- number of categories (3 for football)\n",
    "    '''\n",
    "    value_vec = [0, 0, 0]\n",
    "    \n",
    "    # Bring value_vec into 1, 0, 2 order\n",
    "    if actual_value == 0:\n",
    "        value_vec[1] = 1\n",
    "    elif actual_value == 2:\n",
    "        value_vec[0] == 1\n",
    "    elif actual_value == 1:\n",
    "        value_vec[2] == 1\n",
    "    else:\n",
    "        raise Exception('Prediction was not in [1, 0, 2].')\n",
    "    #value_vec = [0, 0, 1]\n",
    "    \n",
    "    #pred[0], pred[1] = pred[1], pred[0]\n",
    "    \n",
    "    pred[0], pred[1], pred[2] = pred[2], pred[0], pred[1]   # order: loss, draw, win\n",
    "    \n",
    "    #print(pred)\n",
    "    \n",
    "    rps = 0\n",
    "    \n",
    "    for i in range(0, r-1):    # r-1 becomes r because of the exclusion of range()\n",
    "        bracket_part = 0\n",
    "        for j in range(0, i+1):    # same for i and i+1\n",
    "            bracket_part += pred[j] - value_vec[j]\n",
    "        \n",
    "        rps += np.square(bracket_part)\n",
    "    \n",
    "    rps *= 1 / (r - 1)\n",
    "    \n",
    "    return rps\n",
    "\n",
    "\n",
    "# To be used as eval_metric parameter\n",
    "def rps_eval_metric(y_true, y_pred):\n",
    "    return rps(y_pred, y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apparently the random states are pretty important. 21 works very well on RPS and test accuracy, 16 only on accuracy.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.222, random_state=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find best value for *n_estimators*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-mlogloss:1.05159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python38\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalidation_0-mlogloss:1.02520\n",
      "[2]\tvalidation_0-mlogloss:1.00897\n",
      "[3]\tvalidation_0-mlogloss:0.99943\n",
      "[4]\tvalidation_0-mlogloss:0.99461\n",
      "[5]\tvalidation_0-mlogloss:0.98913\n",
      "[6]\tvalidation_0-mlogloss:0.98577\n",
      "[7]\tvalidation_0-mlogloss:0.98409\n",
      "[8]\tvalidation_0-mlogloss:0.98478\n",
      "[9]\tvalidation_0-mlogloss:0.98430\n",
      "[10]\tvalidation_0-mlogloss:0.98471\n",
      "[11]\tvalidation_0-mlogloss:0.98532\n",
      "[12]\tvalidation_0-mlogloss:0.98546\n",
      "[13]\tvalidation_0-mlogloss:0.98485\n",
      "[14]\tvalidation_0-mlogloss:0.98523\n",
      "[15]\tvalidation_0-mlogloss:0.98631\n",
      "[16]\tvalidation_0-mlogloss:0.98643\n",
      "[17]\tvalidation_0-mlogloss:0.98745\n",
      "[18]\tvalidation_0-mlogloss:0.98898\n",
      "[19]\tvalidation_0-mlogloss:0.99127\n",
      "[20]\tvalidation_0-mlogloss:0.99189\n",
      "[21]\tvalidation_0-mlogloss:0.99234\n",
      "[22]\tvalidation_0-mlogloss:0.99355\n",
      "[23]\tvalidation_0-mlogloss:0.99401\n",
      "[24]\tvalidation_0-mlogloss:0.99533\n",
      "[25]\tvalidation_0-mlogloss:0.99560\n",
      "[26]\tvalidation_0-mlogloss:0.99618\n",
      "[27]\tvalidation_0-mlogloss:0.99740\n",
      "[28]\tvalidation_0-mlogloss:0.99772\n",
      "[29]\tvalidation_0-mlogloss:0.99915\n",
      "[30]\tvalidation_0-mlogloss:0.99921\n",
      "[31]\tvalidation_0-mlogloss:0.99964\n",
      "[32]\tvalidation_0-mlogloss:1.00000\n",
      "[33]\tvalidation_0-mlogloss:1.00201\n",
      "[34]\tvalidation_0-mlogloss:1.00333\n",
      "[35]\tvalidation_0-mlogloss:1.00369\n",
      "[36]\tvalidation_0-mlogloss:1.00436\n",
      "[37]\tvalidation_0-mlogloss:1.00502\n",
      "[38]\tvalidation_0-mlogloss:1.00482\n",
      "[39]\tvalidation_0-mlogloss:1.00612\n",
      "[40]\tvalidation_0-mlogloss:1.00754\n",
      "[41]\tvalidation_0-mlogloss:1.00896\n",
      "[42]\tvalidation_0-mlogloss:1.00979\n",
      "[43]\tvalidation_0-mlogloss:1.01120\n",
      "[44]\tvalidation_0-mlogloss:1.01267\n",
      "[45]\tvalidation_0-mlogloss:1.01460\n",
      "[46]\tvalidation_0-mlogloss:1.01649\n",
      "[47]\tvalidation_0-mlogloss:1.01642\n",
      "[48]\tvalidation_0-mlogloss:1.01676\n",
      "[49]\tvalidation_0-mlogloss:1.01686\n"
     ]
    }
   ],
   "source": [
    "# We start with n_estimators=50...\n",
    "xgb_cl = xgb.XGBClassifier(objective='multi:softmax', n_estimators=50, seed=16)\n",
    "# ...and then validate it to find the lowest loss.\n",
    "op = xgb_cl.fit(X_train, y_train, early_stopping_rounds=900, eval_metric='mlogloss', eval_set=[(X_test, y_test)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = [0.001, 0.01, 0.1, 0.2, 0.3]\n",
    "n_estimators = [4, 8, 16, 32]\n",
    "param_grid = dict(learning_rate=learning_rate, n_estimators=n_estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python38\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:29:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Best: 0.475635 using {'learning_rate': 0.2, 'n_estimators': 8}\n"
     ]
    }
   ],
   "source": [
    "# I tried to do Grid Search here, but the \n",
    "\n",
    "grid = GridSearchCV(estimator=xgb_cl, param_grid=param_grid, n_jobs=8, cv=3)\n",
    "grid_result = grid.fit(X, y)\n",
    "\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use best parameters to fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_estimators=8 had the lowest loss, so we overwrite the previous model.b\n",
    "xgb_cl = xgb.XGBClassifier(objective='multi:softprob', n_estimators=8, seed=16, learning_rate=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python38\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:55:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.3, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=8, n_jobs=8, num_parallel_tree=1,\n",
       "              objective='multi:softprob', random_state=16, reg_alpha=0,\n",
       "              reg_lambda=1, scale_pos_weight=None, seed=16, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_cl.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.5309795777085496\n"
     ]
    }
   ],
   "source": [
    "preds = xgb_cl.predict(X_test)\n",
    "accuracy = float(np.sum(preds == y_test))/y_test.shape[0]\n",
    "\n",
    "print(f'accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on train set: 0.6137508643682703\n"
     ]
    }
   ],
   "source": [
    "# Looking at train set accuracy to get an intuition of how much the model overfits\n",
    "preds = xgb_cl.predict(X_train)\n",
    "accuracy = float(np.sum(preds == y_train))/y_train.shape[0]\n",
    "\n",
    "print(f'accuracy on train set: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20160546311142438"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predictions in form of [0.2, 0.5, 0.3] in the order of draw, home win, away win.\n",
    "# This is because it gets ordered like 0, 1, 2.\n",
    "proba_preds = xgb_cl.predict_proba(X_test)\n",
    "\n",
    "# List of RPS scores for every game in the test set.\n",
    "# Important to use iloc for y_test, otherwise indices would be wrong\n",
    "rps_list = [rps(pred, y_test.iloc[i]) for i, pred in enumerate(proba_preds)]\n",
    "\n",
    "# Average ranked probability score.\n",
    "np.mean(rps_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
