{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Preprocessing\n",
    "2. Data Extraction\n",
    "3. Data Exploration\n",
    "4. **Model**\n",
    "\n",
    "This file initializes the model and makes predictions too."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature dataframe from pickle file\n",
    "df = pd.read_pickle('feature_frame.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HomeID</th>\n",
       "      <th>AwayID</th>\n",
       "      <th>FTHG</th>\n",
       "      <th>FTAG</th>\n",
       "      <th>FTR</th>\n",
       "      <th>H_WIN_PCT_home</th>\n",
       "      <th>H_DRAW_PCT_home</th>\n",
       "      <th>A_WIN_PCT_home</th>\n",
       "      <th>A_DRAW_PCT_home</th>\n",
       "      <th>H_WIN_PCT_away</th>\n",
       "      <th>...</th>\n",
       "      <th>RND_CNT_league</th>\n",
       "      <th>H_RTG_home</th>\n",
       "      <th>A_RTG_home</th>\n",
       "      <th>H_RTG_away</th>\n",
       "      <th>A_RTG_away</th>\n",
       "      <th>EGD</th>\n",
       "      <th>EPTS_PR_home</th>\n",
       "      <th>EPTS_PR_away</th>\n",
       "      <th>RED_home</th>\n",
       "      <th>RED_away</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3784</th>\n",
       "      <td>43</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>...</td>\n",
       "      <td>34</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.179242</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.597475</td>\n",
       "      <td>0.581824</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2313</th>\n",
       "      <td>29</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>...</td>\n",
       "      <td>38</td>\n",
       "      <td>0.193164</td>\n",
       "      <td>-0.021125</td>\n",
       "      <td>0.057949</td>\n",
       "      <td>-0.070416</td>\n",
       "      <td>0.215347</td>\n",
       "      <td>1.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11998</th>\n",
       "      <td>109</td>\n",
       "      <td>116</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.459459</td>\n",
       "      <td>0.243243</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.282051</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>...</td>\n",
       "      <td>38</td>\n",
       "      <td>0.496727</td>\n",
       "      <td>-0.119241</td>\n",
       "      <td>0.149018</td>\n",
       "      <td>-0.397471</td>\n",
       "      <td>0.820838</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8254</th>\n",
       "      <td>81</td>\n",
       "      <td>86</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.410256</td>\n",
       "      <td>0.282051</td>\n",
       "      <td>0.447368</td>\n",
       "      <td>...</td>\n",
       "      <td>38</td>\n",
       "      <td>0.028180</td>\n",
       "      <td>0.059041</td>\n",
       "      <td>0.008454</td>\n",
       "      <td>0.196805</td>\n",
       "      <td>-0.141194</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5792</th>\n",
       "      <td>40</td>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.323529</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>...</td>\n",
       "      <td>34</td>\n",
       "      <td>-0.041956</td>\n",
       "      <td>0.069282</td>\n",
       "      <td>-0.012587</td>\n",
       "      <td>0.230939</td>\n",
       "      <td>-0.226659</td>\n",
       "      <td>1.25</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       HomeID  AwayID  FTHG  FTAG  FTR  H_WIN_PCT_home  H_DRAW_PCT_home  \\\n",
       "3784       43      42     1     2    2        0.450000         0.100000   \n",
       "2313       29      26     1     1    0        0.263158         0.315789   \n",
       "11998     109     116     1     1    0        0.459459         0.243243   \n",
       "8254       81      86     2     1    1        0.638889         0.250000   \n",
       "5792       40      50     3     0    1        0.588235         0.323529   \n",
       "\n",
       "       A_WIN_PCT_home  A_DRAW_PCT_home  H_WIN_PCT_away  ...  RND_CNT_league  \\\n",
       "3784         0.550000         0.150000        0.700000  ...              34   \n",
       "2313         0.157895         0.263158        0.300000  ...              38   \n",
       "11998        0.307692         0.282051        0.230769  ...              38   \n",
       "8254         0.410256         0.282051        0.447368  ...              38   \n",
       "5792         0.294118         0.352941        0.235294  ...              34   \n",
       "\n",
       "       H_RTG_home  A_RTG_home  H_RTG_away  A_RTG_away       EGD  EPTS_PR_home  \\\n",
       "3784     0.000000   -0.179242    0.000000   -0.597475  0.581824          0.50   \n",
       "2313     0.193164   -0.021125    0.057949   -0.070416  0.215347          1.50   \n",
       "11998    0.496727   -0.119241    0.149018   -0.397471  0.820838          1.75   \n",
       "8254     0.028180    0.059041    0.008454    0.196805 -0.141194          1.00   \n",
       "5792    -0.041956    0.069282   -0.012587    0.230939 -0.226659          1.25   \n",
       "\n",
       "       EPTS_PR_away  RED_home  RED_away  \n",
       "3784           0.50         0         2  \n",
       "2313           0.00         0         0  \n",
       "11998          0.25         0         0  \n",
       "8254           1.00         1         0  \n",
       "5792           1.25         0         1  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting target variables and features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If True, the goal difference for a specific game is seen as the target variable.\n",
    "# (e.g. -3 for a game outcome of 1:4, or 2 for 3:1) .\n",
    "#\n",
    "# If False, we just want to predict the winner.\n",
    "# 1 = Home team wins, 0 = Draw, 2 = Away team wins\n",
    "predict_goal_difference = False\n",
    "\n",
    "if predict_goal_difference:\n",
    "    y = df['FTHG'] - df['FTAG']\n",
    "else:\n",
    "    y = df['FTR']\n",
    "\n",
    "X = df.iloc[:,5:]    # Remove unnecessary columns (IDs etc.) from features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ranked Probability Score (RPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rps(pred, actual_value, r=3):\n",
    "    '''Returns the ranked probability score for a single given game.\n",
    "    (see Hubacek paper for formula)\n",
    "    \n",
    "    Arguments:\n",
    "    pred -- predicted results; in vector form (e.g. [0.1, 0.6, 0.3])\n",
    "    actual_value -- actual result (0, 1 or 2); not in vector form yet\n",
    "    r -- number of categories (3 for football)\n",
    "    '''\n",
    "    value_vec = [0, 0, 0]\n",
    "    \n",
    "    # Bring value_vec into 1, 0, 2 order\n",
    "    if actual_value == 0:\n",
    "        value_vec[1] = 1\n",
    "    elif actual_value == 2:\n",
    "        value_vec[0] == 1\n",
    "    elif actual_value == 1:\n",
    "        value_vec[2] == 1\n",
    "    else:\n",
    "        raise Exception('Prediction was not in [1, 0, 2].')\n",
    "    #value_vec = [0, 0, 1]\n",
    "    \n",
    "    #pred[0], pred[1] = pred[1], pred[0]\n",
    "    \n",
    "    pred[0], pred[1], pred[2] = pred[2], pred[0], pred[1]   # order: loss, draw, win\n",
    "    \n",
    "    #print(pred)\n",
    "    \n",
    "    rps = 0\n",
    "    \n",
    "    for i in range(0, r-1):    # r-1 becomes r because of the exclusion of range()\n",
    "        bracket_part = 0\n",
    "        for j in range(0, i+1):    # same for i and i+1\n",
    "            bracket_part += pred[j] - value_vec[j]\n",
    "        \n",
    "        rps += np.square(bracket_part)\n",
    "    \n",
    "    rps *= 1 / (r - 1)\n",
    "    \n",
    "    return rps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apparently the random states are pretty important. 21 works very well on RPS and test accuracy, 16 only on accuracy.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.222, random_state=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find best value for *n_estimators*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-mlogloss:1.05159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python38\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalidation_0-mlogloss:1.02520\n",
      "[2]\tvalidation_0-mlogloss:1.00897\n",
      "[3]\tvalidation_0-mlogloss:0.99943\n",
      "[4]\tvalidation_0-mlogloss:0.99461\n",
      "[5]\tvalidation_0-mlogloss:0.98913\n",
      "[6]\tvalidation_0-mlogloss:0.98577\n",
      "[7]\tvalidation_0-mlogloss:0.98409\n",
      "[8]\tvalidation_0-mlogloss:0.98478\n",
      "[9]\tvalidation_0-mlogloss:0.98430\n",
      "[10]\tvalidation_0-mlogloss:0.98471\n",
      "[11]\tvalidation_0-mlogloss:0.98532\n",
      "[12]\tvalidation_0-mlogloss:0.98546\n",
      "[13]\tvalidation_0-mlogloss:0.98485\n",
      "[14]\tvalidation_0-mlogloss:0.98523\n",
      "[15]\tvalidation_0-mlogloss:0.98631\n",
      "[16]\tvalidation_0-mlogloss:0.98643\n",
      "[17]\tvalidation_0-mlogloss:0.98745\n",
      "[18]\tvalidation_0-mlogloss:0.98898\n",
      "[19]\tvalidation_0-mlogloss:0.99127\n",
      "[20]\tvalidation_0-mlogloss:0.99189\n",
      "[21]\tvalidation_0-mlogloss:0.99234\n",
      "[22]\tvalidation_0-mlogloss:0.99355\n",
      "[23]\tvalidation_0-mlogloss:0.99401\n",
      "[24]\tvalidation_0-mlogloss:0.99533\n",
      "[25]\tvalidation_0-mlogloss:0.99560\n",
      "[26]\tvalidation_0-mlogloss:0.99618\n",
      "[27]\tvalidation_0-mlogloss:0.99740\n",
      "[28]\tvalidation_0-mlogloss:0.99772\n",
      "[29]\tvalidation_0-mlogloss:0.99915\n",
      "[30]\tvalidation_0-mlogloss:0.99921\n",
      "[31]\tvalidation_0-mlogloss:0.99964\n",
      "[32]\tvalidation_0-mlogloss:1.00000\n",
      "[33]\tvalidation_0-mlogloss:1.00201\n",
      "[34]\tvalidation_0-mlogloss:1.00333\n",
      "[35]\tvalidation_0-mlogloss:1.00369\n",
      "[36]\tvalidation_0-mlogloss:1.00436\n",
      "[37]\tvalidation_0-mlogloss:1.00502\n",
      "[38]\tvalidation_0-mlogloss:1.00482\n",
      "[39]\tvalidation_0-mlogloss:1.00612\n",
      "[40]\tvalidation_0-mlogloss:1.00754\n",
      "[41]\tvalidation_0-mlogloss:1.00896\n",
      "[42]\tvalidation_0-mlogloss:1.00979\n",
      "[43]\tvalidation_0-mlogloss:1.01120\n",
      "[44]\tvalidation_0-mlogloss:1.01267\n",
      "[45]\tvalidation_0-mlogloss:1.01460\n",
      "[46]\tvalidation_0-mlogloss:1.01649\n",
      "[47]\tvalidation_0-mlogloss:1.01642\n",
      "[48]\tvalidation_0-mlogloss:1.01676\n",
      "[49]\tvalidation_0-mlogloss:1.01686\n"
     ]
    }
   ],
   "source": [
    "# We start with n_estimators=50...\n",
    "xgb_cl = xgb.XGBClassifier(objective='multi:softmax', n_estimators=50, seed=16)\n",
    "# ...and then validate it to find the lowest loss.\n",
    "op = xgb_cl.fit(X_train, y_train, early_stopping_rounds=900, eval_metric='mlogloss', eval_set=[(X_test, y_test)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = [0.001, 0.01, 0.1, 0.2, 0.3]\n",
    "n_estimators = [4, 8, 16, 32]\n",
    "param_grid = dict(learning_rate=learning_rate, n_estimators=n_estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python38\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:29:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Best: 0.475635 using {'learning_rate': 0.2, 'n_estimators': 8}\n"
     ]
    }
   ],
   "source": [
    "# I tried to do Grid Search here, but the \n",
    "\n",
    "grid = GridSearchCV(estimator=xgb_cl, param_grid=param_grid, n_jobs=8, cv=3)\n",
    "grid_result = grid.fit(X, y)\n",
    "\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use best parameters to fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_estimators=8 had the lowest loss, so we overwrite the previous model.b\n",
    "xgb_cl = xgb.XGBClassifier(objective='multi:softprob', n_estimators=8, seed=16, learning_rate=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python38\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:11:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.3, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=8, n_jobs=8, num_parallel_tree=1,\n",
       "              objective='multi:softprob', random_state=16, reg_alpha=0,\n",
       "              reg_lambda=1, scale_pos_weight=None, seed=16, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_cl.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.5264797507788161\n"
     ]
    }
   ],
   "source": [
    "preds = xgb_cl.predict(X_test)\n",
    "accuracy = float(np.sum(preds == y_test))/y_test.shape[0]\n",
    "\n",
    "print(f'accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on train set: 0.613948434258619\n"
     ]
    }
   ],
   "source": [
    "# Looking at train set accuracy to get an intuition of how much the model overfits\n",
    "preds = xgb_cl.predict(X_train)\n",
    "accuracy = float(np.sum(preds == y_train))/y_train.shape[0]\n",
    "\n",
    "print(f'accuracy on train set: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20156425834036565"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predictions in form of [0.2, 0.5, 0.3] in the order of draw, home win, away win.\n",
    "# This is because it gets ordered like 0, 1, 2.\n",
    "proba_preds = xgb_cl.predict_proba(X_test)\n",
    "\n",
    "# List of RPS scores for every game in the test set.\n",
    "# Important to use iloc for y_test, otherwise indices would be wrong\n",
    "rps_list = [rps(pred, y_test.iloc[i]) for i, pred in enumerate(proba_preds)]\n",
    "\n",
    "# Average ranked probability score.\n",
    "np.mean(rps_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
